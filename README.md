# Close Category Generalization

This repository contains the code of the experiments in the paper

[Close Category Generalization]()

Authors: [Yao-Yuan Yang](https://github.com/yangarbiter/), [Cyrus Rashtchian](http://www.cyrusrashtchian.com), [Ruslan Salakhutdinov](https://www.cs.cmu.edu/~rsalakhu/), [Kamalika Chaudhuri](http://cseweb.ucsd.edu/~kamalika/)

## Abstract

Out-of-distribution generalization is a core challenge in machine learning. We introduce and propose a solution to a new type of out-of-distribution evaluation, which we call __close category generalization__. This task specifies how a classifier should extrapolate to unseen classes by considering a bi-criteria objective: (i) on in-distribution examples, output the correct label, and (ii) on out-of-distribution examples, output the label of the nearest neighbor in the training set. In addition to formalizing this problem, we present a new training algorithm to improve the close category generalization of neural networks. We compare to many baselines, including robust algorithms and out-of-distribution detection methods, and we show that our method has better or comparable close category generalization. Then, we investigate a related representation learning task, and we find that performing well on close category generalization correlates with learning a good representation of an unseen class and with finding a good initialization for few-shot learning.

## The source code will be made available soon.
